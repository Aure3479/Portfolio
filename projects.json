{
  "projects": [
    {
      "title": "Tic Tac Cheers (Tic Tac Toe Marque-verre)",
      "subtitle": "produit Kickstarter • cuir upcyclé",
      "color": "#0ea5e9",
      "bg": "#ffffff",
      "description": "Un marque-verre pour verre à pied, pensé comme un mini “morpion” : tu poses X ou O autour de la tige et tu retrouves instantanément ton verre. Le projet combine l’objet utile (anti-confusion), le jeu (tactile, convivial) et l’upcycling (petites chutes de cuir) dans une forme simple, robuste et agréable en main.",
      "details": "L’idée est née d’un problème banal mais universel : autour d’une table, les verres se ressemblent, se déplacent, et on perd vite le fil. Plutôt que d’imprimer des étiquettes ou de multiplier les gadgets, moi et mon équipe avons cherché une solution “premium” et durable : un système de marqueurs minimalistes, réutilisables, et assez beaux pour rester sur la table.\n\nEn soit tout ceci est, par le biais du kickstarter, une représentation en 6 mois de la méthodologie de création de produit, conceptualiser, voir les ressources néssaire (qualité + fournisseur), pour finir au marketing + livraison.\n\n Le résultat : un jeu qui devient un marqueur, et un marqueur qui donne un prétexte à jouer.",
      "link": "https://www.kickstarter.com/projects/2046457781/347053131?ref=ao76zu&token=b8ae7ef8",
      "linkLabel": "Voir la page Kickstarter",
      "image": "images/marque_verre.png",
      "caption": "Concept : des X/O en cuir qui s’accrochent à la tige",
      "key-words": ["Prototypage", "Design produit", "Expérience utilisateur", "Cuir", "Kickstarter"],
      "keywordsShared": ["Prototypage", "Design produit", "Expérience utilisateur"],
      "keywordsUnique": ["Cuir", "Kickstarter"]
    },
    {
      "title": "ActionTypes – POC (vision par ordinateur)",
      "subtitle": "protocole + pipeline de features",
      "color": "#f59e0b",
      "bg": "#ffffff",
      "description": "Un POC de recherche appliquée pour explorer la détection de préférences motrices via vidéo : posture, marche, engagement du corps, stabilité, et signaux complémentaires (voix / respiration). L’objectif n’est pas de “deviner une personnalité”, mais de bâtir une base méthodologique : capter, extraire, mesurer, puis décrire des régularités de mouvement de manière reproductible.",
      "details": "Ce projet est structuré comme une démarche de recherche : partir d’hypothèses observables, construire un protocole minimal mais solide à partir de connaissances de la méthodologie Actiontypes, puis tester une chaîne technique de bout en bout. La première étape consiste à cadrer ce qui est mesurable à faible coût : angles articulaires, amplitude, symétries, bascules, micro-stabilisations, et patterns sur des tâches simples (marcher, se retourner le tout face à une caméra).\n\nEnsuite vient le pipeline vision : capture vidéo → extraction de points-clés (keypoints) → reconstruction de features (angles, vitesses, ratios, trajectoires) → analyse descriptive (comparaisons intra-individu / inter-individus).\n\nEnfin, le projet intègre une dimension produit : imaginer un usage praticien (live vs post-traitement), des contraintes d’accessibilité (captation simple, consignes courtes), et un chemin de validation progressif (petits tests, itérations, documentation). Le livrable vise à être autant une base technique qu’une base narrative : un protocole clair, des choix justifiés, et des limites posées noir sur blanc.",
      "link": null,
      "linkLabel": null,
      "image": "images/ata.png",
      "caption": "De la captation à l’analyse : keypoints → features → interprétation",
      "key-words": ["Recherche appliquée", "Vision par ordinateur", "Analyse de données", "Préférences motrices", "Protocole expérimental"],
      "keywordsShared": ["Recherche appliquée", "Vision par ordinateur", "Analyse de données"],
      "keywordsUnique": ["Préférences motrices", "Protocole expérimental"]
    },
    {
      "title": "Apiculture – suivi terrain via WebNFC",
      "subtitle": "web app • ruches, reines & interventions",
      "color": "#facc15",
      "bg": "#ffffff",
      "description": "Une application web orientée terrain pour accélérer le suivi apicole grâce à WebNFC : identifier une ruche en un geste non parasite lors des fonctions d'un apiculteur, enregistrer une intervention rapidement, tracer l’historique, et réduire la friction au maximum (mains prises, météo, timing serré).",
      "details": "L’ambition du projet est très pragmatique : en apiculture, la valeur est dans la régularité des observations et la qualité de la traçabilité… mais c’est justement ce qui est le plus pénible à saisir sur le terrain. Le choix WebNFC permet un accès immédiat à la bonne “fiche ruche” sans navigation : on scanne, on agit.\n\nLe cœur du travail a été de transformer des actions métier (visite, état de reine, fécondation, introduction, récolte, préparation) en un flux de saisie ultra-court qui est storé localement et accessible en temps hors-terrain. J’ai structuré l’information pour qu’elle reste exploitable : événements horodatés, champs cohérents, et logique d’états. Une partie importante du projet est la robustesse : éviter les erreurs de saisie, gérer les cas incomplets tout en restant flexible, et garder une utilisation fluide même si l’utilisateur est pressé.\n\nLe projet est aussi un terrain d’expérimentation produit : comment concevoir une web app “mobile-first” qui privilégie l’action plutôt que l’interface, comment rendre l’historique lisible, et comment préparer l’intégration future de données (balance connectée, météo, notes vocales, etc.). Le résultat est une base solide pour itérer : un outil simple, mais pensé pour durer et s’adapter à la réalité du rucher.",
      "link": "https://apifolio.pass-abeilles.fr/",
      "linkLabel": "Ouvrir l’application",
      "image": "images/bee.png",
      "caption": "Scan NFC → fiche ruche → action enregistrée",
      "key-words": ["Produit web", "Expérience utilisateur", "Traçabilité", "WebNFC", "Apiculture"],
      "keywordsShared": ["Produit web", "Expérience utilisateur", "Traçabilité"],
      "keywordsUnique": ["WebNFC", "Apiculture"]
    },
    {
      "title": "WebSocket – transmission de couleurs",
      "subtitle": "UI temps réel + design Figma",
      "color": "#22c55e",
      "bg": "#ffffff",
      "description": "Un mini-système temps réel où une couleur choisie côté UI est transmise via WebSocket, puis confirmée par un retour positif ou négatif (ACK/NACK). Le projet mélange logique réseau (état, synchro, résilience) et design d’interface (feedback clair, micro-interactions, prototype Figma → implémentation).",
      "details": "Ce projet a été pensé comme un exercice complet de “boucle de feedback” : l’utilisateur fait une action visuelle simple (sélectionner une couleur), le système la transmet en temps réel, puis renvoie une confirmation explicite. Cela permet de créer un sorte d'échange ou une personne envoie une couleur à un autre pour que ce dernier 'valide ou non la couleur'.\n\nCôté technique, le point clé est la gestion d’état : éviter les incohérences (couleur affichée ≠ couleur validée), gérer les latences, et distinguer trois moments dans l’UX : intention → envoi → validation. Côté UI, le travail se concentre sur la lisibilité : comment signaler un échec sans agresser, comment guider la correction, et comment rendre le tout agréable avec un design minimal.\n\nLe projet a aussi une dimension méthodo : partir d’une maquette Figma, traduire en composants, puis garder une cohérence entre conception et implémentation. Le résultat est un mini “pattern” réutilisable pour d’autres interfaces temps réel (IoT, dashboards, contrôle à distance, etc.).",
      "link": "https://github.com/Aure3479/web_UI_workshop/tree/main",
      "linkLabel": "Voir le repo (implémentation)",
      "image": "images/web_socket.png",
      "caption": "Couleur envoyée → réponse ACK/NACK → UI mise à jour",
      "key-words": ["Temps réel", "Produit web", "Design d’interface", "WebSocket", "ACK/NACK"],
      "keywordsShared": ["Temps réel", "Produit web", "Design d’interface"],
      "keywordsUnique": ["WebSocket", "ACK/NACK"]
    },
    {
      "title": "Pygame: audio survival game",
      "subtitle": "gameplay audio + test utilisateur",
      "color": "#f43f5e",
      "bg": "#ffffff",
      "description": "Un prototype de jeu de survie conçu autour de signaux sonores : la musique n’est pas un décor, c’est une information. Le projet inclut une logique de gameplay, des règles lisibles, et une user study complète pour observer comment les joueurs ont agis en fonction du retour autant visuel qu’auditif.",
      "details": "L'idée est de créer un jeu de rythme d'où la difficulté est généré en fonction de la musique choisit , permettant ainsi de créer un modèle semi automatique qui peut créer un 'niveau' en fonction d'une musique. Le gameplay est centré sur la survie : le joueur doit éviter de se faire toucher par des ennemis qui apparaissent en rythme avec la musique d'une manière plus ou moins rapide, avec une récompense plus ou moins haute en fonction du rapprochement de l'ennemi au joueur avant de se faire éliminer \n Tout ceci dans l'idée de créer un user study complet d'une situation ou d'un protocole.",
      "link": "https://github.com/Aure3479/Python-small-video-game",
      "linkLabel": "Voir le repo",
      "image": "images/pygame.png",
      "caption": "Survie guidée par indices sonores",
      "key-words": ["Prototypage", "Expérience utilisateur", "Test utilisateur", "Jeu audio", "Pygame"],
      "keywordsShared": ["Prototypage", "Expérience utilisateur", "Test utilisateur"],
      "keywordsUnique": ["Jeu audio", "Pygame"]
    },
    {
      "title": "Raymarching test ",
      "subtitle": "SDF • rendu temps réel • prototype 3D",
      "color": "#0b1320",
      "bg": "#ffffff",
      "description": "Un mini-jeu construit sur du raymarching (Signed Distance Fields) : un univers 3D généré par des fonctions, rendu en temps réel, où le paysage naît directement des capacité du moteur (distance, collisions, perception).",
      "details": "Le raymarching est une approche fascinante parce qu’elle force une autre manière de penser : au lieu de modéliser des objets, on définit des formes mathématiques. Le monde devient un ensemble de fonctions, et le rendu consiste à “marcher” dans l’espace pour trouver les surfaces. Cette mécanique ouvre un terrain créatif énorme : géométries impossibles, transitions fluides, surfaces organiques.\n\nLe projet se concentre sur un prototype jouable et compréhensible : caméra, déplacement, limites de collision, lisibilité spatiale, et optimisation minimale (itérations de marche, précision, clipping). Le défi principal est d’équilibrer la beauté du rendu avec la stabilité : un jeu doit rester fluide et prévisible.\n\nCe projet sert aussi de vitrine technique : il démontre une capacité à transformer un concept graphique/algorithmique en expérience interactive, avec une base propre pour itérer (effets, niveaux, objectifs, UI).",
      "link": "https://github.com/Aure3479/AICGraymarching",
      "linkLabel": "Voir le repo",
      "image": "images/raymarching.png",
      "caption": "Monde SDF rendu par raymarching",
      "key-words": ["Prototypage", "Rendu temps réel", "Jeu", "Raymarching", "SDF"],
      "keywordsShared": ["Prototypage", "Rendu temps réel", "Jeu"],
      "keywordsUnique": ["Raymarching", "SDF"]
    },
    {
      "title": "Text RPG, WebLLM",
      "subtitle": "LLM dans le navigateur • narration interactive",
      "color": "#6366f1",
      "bg": "#ffffff",
      "description": "Un RPG texte jouable dans le navigateur, propulsé par un modèle de langage exécuté localement (WebLLM). Le projet explore la narration interactive, la gestion d’état (inventaire, scènes, choix), et la qualité d’écriture sous contrainte (cohérence, répétitions, tempo).",
      "details": "Le pari est double : garder l’immédiateté d’un jeu texte (lecture, choix, imagination), tout en bénéficiant de la flexibilité d’un LLM pour générer des scènes dynamiques. Techniquement, cela implique de gérer finement le contexte : ce que le modèle “doit” savoir (état du joueur, lieux, objectifs), ce qu’il faut résumer régulièrement, et comment éviter que l’histoire parte dans tous les sens.\n\nLe projet travaille donc sur des patterns de game state : journal d’événements, inventaire structuré, règles de narration (ton, danger, humour, style), et garde-fous pour maintenir une progression. \n\nC’est un projet à but de tester le prompt engeniering à relativement haut niveau (en tout cas à l'époque). Il montre comment on peut transformer une techno IA en vraie expérience interactive, sans l’utiliser comme “magie” mais comme moteur sous contrôle.",
      "link": "https://github.com/Aure3479/AI-Text-RPG-",
      "linkLabel": "Voir le repo",
      "image": "images/txt_rpg.png",
      "caption": "RPG texte : état du monde + génération contrôlée",
      "key-words": ["Produit web", "Jeu", "IA appliquée", "WebLLM", "Narration interactive"],
      "keywordsShared": ["Produit web", "Jeu", "IA appliquée"],
      "keywordsUnique": ["WebLLM", "Narration interactive"]
    },
    {
      "title": "Annoying password",
      "subtitle": "p5.js • détection tête/visage • WarioWare vibe",
      "color": "#10b981",
      "bg": "#ffffff",
      "description": "Un prototype volontairement absurde : saisir un mot de passe via des micro-interactions basées sur la détection de tête/visage (et une logique “mini-jeu”). L’objectif est moins la sécurité que l’exploration HCI : friction, attention, accessibilité, et ce que l’interface “exige” de l’utilisateur.",
      "details": "Ce projet a un angle expérimental : pousser une interaction au-delà du raisonnable pour observer ce que ça provoque. Au lieu de taper un mot de passe, l’utilisateur doit réussir une séquence d’actions basée sur des signaux détectés, le clignement des yeux pour faire du morse (gauche pour les point et droite pour les traits, ouvrir la bouche pour valider et perte de la vision du visage pour annuler). C’est le genre d’idée qui fait sourire… mais qui ouvre de vrais sujets : charge cognitive, fatigue, robustesse du tracking, et tolérance aux erreurs.\n\nLe livrable se lit comme une démonstration de creative coding + interaction design : un prototype mémorable, qui raconte une histoire et montre une capacité à prototyper vite une idée originale (même volontairement irritante).",
      "link": "https://github.com/ISDriss/Warioware-numbers/blob/main/blink%20morse%20hell/demo-blink.mp4",
      "linkLabel": "Voir la démo vidéo",
      "image": "images/morse_pwd.png",
      "caption": "Authentification absurde (concept HCI)",
      "key-words": ["Prototypage", "Interaction homme-machine", "Vision par ordinateur", "p5.js", "Authentification alternative"],
      "keywordsShared": ["Prototypage", "Interaction homme-machine", "Vision par ordinateur"],
      "keywordsUnique": ["p5.js", "Authentification alternative"]
    }
  ]
}
